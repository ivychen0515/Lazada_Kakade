{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/kakade/spark')\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "spark = SparkSession.builder.appName(\"kakade\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,StringType,FloatType,StructType\n",
    "#Add header to data feature\n",
    "feature_schema = [StructField(\"country\", StringType(), True), StructField(\"sku_id\", StringType(), True), \\\n",
    "                  StructField(\"title\",StringType(), True), StructField(\"category_1\",StringType(), True), \\\n",
    "                  StructField(\"category_2\",StringType(), True), StructField(\"category_3\",StringType(), True), \\\n",
    "                  StructField(\"description\",StringType(), True), StructField(\"org_price\", FloatType(), True), \\\n",
    "                  StructField(\"product_type\",StringType(), True)]\n",
    "# country sku_id title category_1 category_2 category_3 short_description price product_type \n",
    "feature_struc = StructType(fields=feature_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = spark.read.csv(\"../Data/training/data_train.csv\",escape='\"',schema=feature_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0c2b4caa3ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train_feature.groupBy(\"category_1\").count().orderBy(\"count\",ascending=False).show(truncate=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmain_category\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"category_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count>5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_feature.category_1\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"main_category.category_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'col' is not defined"
     ]
    }
   ],
   "source": [
    "#most other category only contain <=5 products\n",
    "#filter products out of the main categories\n",
    "# train_feature.groupBy(\"category_1\").count().orderBy(\"count\",ascending=False).show(truncate=False)\n",
    "main_category=train_feature.groupBy(\"category_1\").count().filter(\"count>5\")\n",
    "train_feature = train_feature.join(main_category, col(\"train_feature.category_1\") == col(\"main_category.category_1\"), 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer,StopWordsRemover,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_extract_func(col):\n",
    "    soup=BeautifulSoup(col)\n",
    "    return soup.get_text()\n",
    "    return (1-col1/col2)**2\n",
    "html_extract = udf(html_extract_func, StringType())\n",
    "train_feature = train_feature.withColumn(\"html_extract\",html_extract(\"description\"))\n",
    "# train_feature.select(\"html_extract\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- sku_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- category_1: string (nullable = true)\n",
      " |-- category_2: string (nullable = true)\n",
      " |-- category_3: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- org_price: float (nullable = true)\n",
      " |-- product_type: string (nullable = true)\n",
      " |-- html_extract: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feature.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|stop_words_filtered                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[material, non, sheer, shimmer, chiffonsizes, x, inches, x, inchescut, curved, ends]                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|[formulated, oil, free, hydrating, botanicals, remarkably, improves, skin, texture, abused, hands, restores, soft, smooth, refined, hands]                                                                                                                                                                                                                                                                                                                                           |\n",
      "|[cm, mini, microphone, compatible, iphone, various, smartphones, also, ipad, apple, computer, macbook, dual, headed, design, allows, two, people, using, simultaneously, features, high, sensitivity, omni, directional, sounds, output, perfect, audio, video, recording, mm, standard, connector, jack, convenient, clip, design, clip, collar, mm, standard, connector, jack, convenient, clip, design, clip, collar]                                                             |\n",
      "|[anmyna, complaint, silky, set, shampoo, ml, conditioner, ml, deep, nourish, repair, damaged, hair, protect, scalp, prevent, hair, loss]                                                                                                                                                                                                                                                                                                                                             |\n",
      "|[authentic, rrefresh, brighten, skin, anti, wrinkle, deep, cleansing, effects]                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "|[genuine, windows, hd, touch, intel, core, u, gb, ram, gb, rom, nvidia, geforce, gt, m, card, reader, sd, sdhc, vga, web, camera, asus, sonicmaster, lite, technology]                                                                                                                                                                                                                                                                                                               |\n",
      "|[color, temperature, k, ra, voltage, v, v, power, w, w, diameter, cm, inner, outer, weight, g]                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "|[reviving, like, new, born, baby, age, apply, age, net, content, app, g, pair, guarantee, period, years]                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "|[designed, constructed, super, speed, usb, specifications, extend, usb, port, pc, laptop, practical, spot, desktop, enables, throughput, gbps, used, usb, host, device, backwards, compatible, usb, usb, specification, convenient, slim, flat, cable, design, ultra, flexible, tangle, free]                                                                                                                                                                                        |\n",
      "|[genuine, issued, mcdonald, coca, cola, merchandize, limited, edition, collection, brand, new, paper, packaging, color, purple, limited, stock, left, second, chance, ideal, putting, drink, beverage, even, coke, even, ideal, keeping, coca, cola, museum, free, shipping]                                                                                                                                                                                                         |\n",
      "|[stainless, steel, filter, stainless, tea, filter, tea, ball, filter]                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "|[material, genuine, prehnite, crystal, beads, size, mm, beads, length, cm, stretchy]                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|[lead, nickle, free, good, quality, free, shipping, enough, stock]                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|[accurately, track, day, stats, like, steps, taken, distance, traveled, calories, burned, stairs, climbed, active, minutes, see, daily, stats, time, day, bright, oled, display, monitor, long, well, sleep, wake, silent, vibrating, alarm, get, call, notifications, right, wrist, access, real, time, run, stats, like, time, distance, pace, stay, track, sync, stats, wirelessly, automatically, computer, leading, smartphones]                                                |\n",
      "|[apply, morning, evening, eyelash, treatment, excellent, occular, tolerability]                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "|[brand, new, high, quality, fashion, men, business, shoes, pu, leather, lace, shoes, type, formal, shoes, gender, men, material, pu, rubber, sole, color, brown, black, asian, size]                                                                                                                                                                                                                                                                                                 |\n",
      "|[gender, men, movement, mechanical, movement, type, automatic, self, wind, type, skeleton, watch, display, analog, case, material, alloy, dial, color, black, case, diameter, mm, case, diameter, approx, mm, case, thickness, approx, mm, band, color, black, band, material, stailess, steel, band, length, approx, cm, band, width, approx, cm, net, weight, kg]                                                                                                                  |\n",
      "|[print, sides, glossy, finish, diy, customize, images, designs, text, slim, profile, lightweight, impact, resistant, durable, hard, plastic, access, ports, controls, sensors, lay, flat, bezel, protect, screen, directly, contacting, surfaces, keep, nice, mood, every, day, best, valentine, day, christmas, birthday, hallowmas, little, gift, girls, boys, women, men, friends, family, new, fashionable, cute, lovely, funny, cool, useful, cheap, excellent, choices, jianse]|\n",
      "|[item, type, phone, holder, size, x, x, cm, material, alloy, pvc, compatible, phone, model, inches, color, light, blue]                                                                                                                                                                                                                                                                                                                                                              |\n",
      "|[genuine, authentic, products, free, fast, shipping, buy, confidence]                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "des_cat_test = train_feature.select(\"category_1\",\"sku_id\",F.regexp_replace(train_feature.html_extract, '(\\d+)', ' ').alias('html_extract'))\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"html_extract\", outputCol=\"description_token\", pattern=\"\\\\W\")\n",
    "des_cat_test = regexTokenizer.transform(des_cat_test)\n",
    "stop_words_remover = StopWordsRemover(inputCol=\"description_token\", outputCol=\"stop_words_filtered\")\n",
    "des_cat_test = stop_words_remover.transform(des_cat_test)\n",
    "des_cat_test.select(\"stop_words_filtered\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##currency_exchange\n",
    "#set all price to PHP\n",
    "import pyspark.sql.functions as F\n",
    "from forex_python.converter import CurrencyRates\n",
    "cex = CurrencyRates()\n",
    "S2P=cex.get_rate(\"SGD\",\"PHP\")\n",
    "M2P=cex.get_rate(\"MYR\",\"PHP\")\n",
    "train_feature=train_feature.withColumn(\"price\", F.when(train_feature.country == \"my\", M2P*train_feature.org_price).when(train_feature.country == \"sg\", S2P*train_feature.org_price).otherwise(train_feature.org_price))\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|             price|org_price|\n",
      "+------------------+---------+\n",
      "|            597.31|     49.0|\n",
      "|           1560.32|    128.0|\n",
      "| 305.6032962799072|    25.07|\n",
      "|1438.4199999999998|    118.0|\n",
      "|1399.4120372009277|    114.8|\n",
      "|31681.809999999998|   2599.0|\n",
      "| 4741.787980957031|   388.99|\n",
      "|126.77599534988403|     10.4|\n",
      "|               0.0|      0.0|\n",
      "|            304.75|     25.0|\n",
      "|115.56119441986084|     9.48|\n",
      "| 950.8199999999999|     78.0|\n",
      "|189.55450232505797|    15.55|\n",
      "|6082.8099999999995|    499.0|\n",
      "|            1462.8|    120.0|\n",
      "|              null|     null|\n",
      "| 1031.273981399536|     84.6|\n",
      "|             365.7|     30.0|\n",
      "| 203.0853981399536|    16.66|\n",
      "|2072.2999999999997|    170.0|\n",
      "+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feature.select(\"price\",\"org_price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-----+\n",
      "|category_1                                                    |count|\n",
      "+--------------------------------------------------------------+-----+\n",
      "|Mobiles & Tablets                                             |7273 |\n",
      "|Home & Living                                                 |6042 |\n",
      "|Fashion                                                       |5729 |\n",
      "|Watches Sunglasses Jewellery                                  |4216 |\n",
      "|Health & Beauty                                               |4040 |\n",
      "|Computers & Laptops                                           |2882 |\n",
      "|TV, Audio / Video, Gaming & Wearables                         |2505 |\n",
      "|Cameras                                                       |1950 |\n",
      "|Home Appliances                                               |1583 |\n",
      "| 8GB                                                          |5    |\n",
      "| 4GB                                                          |5    |\n",
      "|A1466)                                                        |2    |\n",
      "| Black\"                                                       |2    |\n",
      "| Direct Shipping &amp; Free Installation in Klang Valley\"     |2    |\n",
      "|Soft-Touch Plastic 13 inch Cover for Apple MacBook Pro 13.3\"\"\"|1    |\n",
      "|W7Pro)\"                                                       |1    |\n",
      "|W10\"                                                          |1    |\n",
      "| Crystal-Black)\"                                              |1    |\n",
      "| BLACK + ASUS ORIGINAL DESIGN BACKPACK\"                       |1    |\n",
      "| W8.1) - FREE Office 365 Personal + Targus Backpack\"          |1    |\n",
      "+--------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "des_cat_test.groupBy(\"category_1\").count().orderBy(\"count\",ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-32-8532e3f6520c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-8532e3f6520c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    cat_train_test = des_cat_test.join(main_category,des_cat_test.category_1=main_category.category_1, 'inner')\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "main_category=des_cat_test.groupBy(\"category_1\").count().filter(\"count>5\")\n",
    "cat_train_test = des_cat_test.join(main_category,des_cat_test.category_1=main_category.category_1, 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            sku_id|\n",
      "+-------+------------------+\n",
      "|  count|             36283|\n",
      "|   mean|              null|\n",
      "| stddev|              null|\n",
      "|    min|1A127ELAA3U0JKANPH|\n",
      "|    max|  ZY795HLCZ3O0ANMY|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feature.select(\"sku_id\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|<ul><li>Material : Non sheer shimmer chiffon</li><li>Sizes : 52 x 52 inches OR 56 x 56 inches</li><li>Cut with curved ends</li></ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "|Formulated with oil-free hydrating botanicals/ Remarkably improves skin texture of abused hands/Restores soft, smooth & refined hands                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "|<ul> <li>150cm mini microphone compatible for iPhone, various smartphones, and also for iPad/ Apple computer/ Macbook.</li> <li>Dual-headed design, allows for two people using simultaneously.</li> <li>Features high sensitivity &amp; omni-directional sounds output, perfect for audio and video recording.</li> <li>3.5mm standard connector jack.</li> <li>Convenient clip-on design, can clip it on your collar.</li> <li>3.5mm standard connector jack. Convenient clip-on design, can clip it on your collar.</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "|<ul> <li>ANMYNA Complaint Silky Set (Shampoo 520ml + Conditioner 250ml)</li> <li>Deep nourish</li> <li>Repair damaged hair</li> <li>Protect the scalp and prevent hair loss</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|<ul> <li>100% Authentic</li> <li>Rrefresh and brighten skin</li> <li>Anti-wrinkle and deep cleansing effects</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "|<div class=\"prod_content\"> <div class=\"prod_details\"> <ul class=\"prd-attributesList ui-listBulleted\"> <li class=\"\">Genuine Windows® 8.1</li> <li class=\"\">13.3in 16:9 HD TOUCH</li> <li class=\"\">Intel® Core™ I5-5200U</li> <li class=\"\">4GB RAM - 500GB ROM</li> <li class=\"\">NVIDIA® GeForce® GT 920M</li> <li class=\"\">2 -in-1 card reader ( SD/ SDHC)</li> <li class=\"\">VGA Web Camera</li> <li class=\"\">ASUS SonicMaster Lite Technology</li> </ul> </div> </div>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|<ul> <li>1. Color Temperature: 5400K</li> <li>2. Ra: &gt;90</li> <li>3. Voltage: 220V/110V</li> <li>4. Power: 40W×1=40W</li> <li>5. Diameter: 235/315cm (inner/outer)</li> <li>6. Weight: 640g</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "|<ul> <li>Reviving like a new born baby.</li> <li>Age:Apply at any age</li> <li>NET content: App 38g/pair</li> <li>Guarantee period: 3 years</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|<ul style= \"padding: 0px; margin: 20px 0px 0px 15px; color: rgb(0, 0, 0); font-family: Arial, Helvetica, sans-serif; font-size: medium; line-height: 16px;\"> <li style= \"padding: 0px; margin: 0px 0px 10px; font-size: 0.8em; text-align: justify;\"> Designed and constructed to super-speed USB 3.0 Specifications.</li> <li style= \"padding: 0px; margin: 0px 0px 10px; font-size: 0.8em; text-align: justify;\"> Extend your USB 3.0 port from your PC or Laptop to a more practical spot on your desktop.</li> <li style= \"padding: 0px; margin: 0px 0px 10px; font-size: 0.8em; text-align: justify;\"> Enables throughput of up to 5Gbps when used with a USB 3.0 host and device.</li> <li style= \"padding: 0px; margin: 0px 0px 10px; font-size: 0.8em; text-align: justify;\"> Backwards compatible with USB 2.0 and USB 1.1 specification.</li> <li style= \"padding: 0px; margin: 0px 0px 10px; font-size: 0.8em; text-align: justify;\"> Convenient Slim Flat cable design is ultra-flexible and tangle-free.</li> </ul> |\n",
      "|<ul> <li>Genuine issued McDonald's Coca Cola merchandize</li> <li>Limited 2010 Edition for Collection</li> <li>Brand New in paper packaging</li> <li>Color : Purple</li> <li>Limited Stock Left, no second chance</li> <li>Ideal for putting drink and beverage, or even the Coke</li> <li>Even more ideal for keeping in your Coca Cola museum</li> <li>Free Shipping</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "|<ul> <li>Stainless Steel Filter</li> <li>Stainless Tea Filter</li> <li>Tea Ball Filter</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "|<ul> <li>Material: Genuine Prehnite Crystal Beads</li> <li>Size: 7mm, 26 beads</li> <li>Length: 16.5cm, Stretchy</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "|<ul> <li>Lead and Nickle Free</li> <li>Good Quality and Free Shipping</li> <li>Enough Stock</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|<ul> <li>Accurately track all-day stats like steps taken, distance traveled, calories burned, stairs climbed, and active minutes</li> <li>See daily stats and time of day with a bright OLED display</li> <li>Monitor how long and how well you sleep, and wake with a silent vibrating alarm Get call notifications right on your wrist</li> <li>Access real-time run stats like time, distance, and pace to stay on track</li> <li>Sync stats wirelessly and automatically to your computer and over 100 leading smartphones</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "|<ul> <li>Apply morning and evening&nbsp;</li> <li>Eyelash treatment&nbsp;</li> <li>Excellent occular tolerability</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|<ul style=\"list-style-type:disc\"> <li>100% Brand New and High Quality</li> <li>Fashion Men Business Shoes</li> <li>PU Leather Lace Up Shoes</li> <li>Type: Formal Shoes</li> <li>Gender: Men</li> <li>Material: PU + Rubber Sole</li> <li>Color: Brown, Black</li> <li>Asian Size: 40, 41, 42, 43, 44, 45, 46</li> </ul> <br> <br>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "|<div> <ul> <li>Gender Men's</li> <li>Movement Mechanical</li> <li>Movement type Automatic Self Wind</li> <li>Type Skeleton Watch</li> <li>Display Analog</li> <li>Case Material Alloy</li> <li>Dial Color Black</li> <li>Case Diameter 40mm</li> <li>Case Diameter Approx 41mm</li> <li>Case Thickness Approx 13mm</li> <li>Band Color Black</li> <li>Band Material Stailess Steel</li> <li>Band Length Approx (CM) 24</li> <li>Band Width Approx (CM) 2</li> <li>Net Weight(kg) 0.04</li> </ul> </div> <div><br></div>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "|<ul> <li>Print on all sides, glossy finish</li> <li>DIY Customize with your images, designs, and text&nbsp;</li> <li>Slim profile and lightweight;Impact resistant, durable hard plastic;Access to all ports, controls &amp; sensors&nbsp;</li> <li>Lay-flat bezel to protect your screen from directly contacting surfaces and keep you in a nice mood every day.</li> <li>It's the best valentine's day christmas birthday Hallowmas little gift for your girls boys women men friends or family,new fashionable cute lovely funny cool but useful and cheap. more excellent choices in Jianse</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "|<ul> <li>Item Type:Phone Holder</li> <li>Size:85 x 12 x 8cm.</li> <li>Material: Alloy + PVC.</li> <li>Compatible Phone Model: 3-7 inches.</li> <li>Color:Light Blue.</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|<ul> <li>100% Genuine and Authentic products</li> <li>Free and Fast Shipping</li> <li>Buy with confidence!</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feature.select(\"description\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(html_extract=' 1. Color Temperature: 5400K 2. Ra: >90 3. Voltage: 220V/110V 4. Power: 40W×1=40W 5. Diameter: 235/315cm (inner/outer) 6. Weight: 640g  ')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.select(\"html_extract\").head(8)[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(description='<ul> <li>1. Color Temperature: 5400K</li> <li>2. Ra: &gt;90</li> <li>3. Voltage: 220V/110V</li> <li>4. Power: 40W×1=40W</li> <li>5. Diameter: 235/315cm (inner/outer)</li> <li>6. Weight: 640g</li> </ul> ')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.select(\"description\").head(8)[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't find model 'en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0725495294d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spaCy/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;34m\"to load. For example:\\nnlp = spacy.load('{}')\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             'error')\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spaCy/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't find model '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't find model 'en'"
     ]
    }
   ],
   "source": [
    "spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import w2v_func\n",
    "import gensim\n",
    "spark.sparkContext.addPyFile('w2v_func.py')\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ent = udf(w2v_func.w2v_func())\n",
    "test=train_feature.filter(train_feature[\"sku_id\"]==\"AD674FAASTLXANMY\")\n",
    "df = test.withColumn(\"test\", title_ent(\"country\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o197.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 4, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 220, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 138, in dump_stream\n    for obj in iterator:\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 209, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 71, in <lambda>\n    return lambda *a: f(*a)\n  File \"/home/kakade/Lazada_Kakade/Spark/w2v_func.py\", line 36, in __call__\n    w2v_model=gensim.models.KeyedVectors.load_word2vec_format('/home/kakade/Support_files/GoogleNews-vectors-negative300.bin', binary=True).word_vec(x)\n  File \"/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\", line 209, in load_word2vec_format\n    result.syn0 = zeros((vocab_size, vector_size), dtype=datatype)\nMemoryError\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:144)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:87)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:336)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:2853)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset$$anonfun$55.apply(Dataset.scala:2837)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:2836)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2366)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:245)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 220, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 138, in dump_stream\n    for obj in iterator:\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 209, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 71, in <lambda>\n    return lambda *a: f(*a)\n  File \"/home/kakade/Lazada_Kakade/Spark/w2v_func.py\", line 36, in __call__\n    w2v_model=gensim.models.KeyedVectors.load_word2vec_format('/home/kakade/Support_files/GoogleNews-vectors-negative300.bin', binary=True).word_vec(x)\n  File \"/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\", line 209, in load_word2vec_format\n    result.syn0 = zeros((vocab_size, vector_size), dtype=datatype)\nMemoryError\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:144)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:87)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1a6ce2362cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \"\"\"\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o197.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 4, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 220, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 138, in dump_stream\n    for obj in iterator:\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 209, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 71, in <lambda>\n    return lambda *a: f(*a)\n  File \"/home/kakade/Lazada_Kakade/Spark/w2v_func.py\", line 36, in __call__\n    w2v_model=gensim.models.KeyedVectors.load_word2vec_format('/home/kakade/Support_files/GoogleNews-vectors-negative300.bin', binary=True).word_vec(x)\n  File \"/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\", line 209, in load_word2vec_format\n    result.syn0 = zeros((vocab_size, vector_size), dtype=datatype)\nMemoryError\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:144)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:87)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:336)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:2853)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset$$anonfun$55.apply(Dataset.scala:2837)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:2836)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2366)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:245)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 220, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 138, in dump_stream\n    for obj in iterator:\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 209, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/home/kakade/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 71, in <lambda>\n    return lambda *a: f(*a)\n  File \"/home/kakade/Lazada_Kakade/Spark/w2v_func.py\", line 36, in __call__\n    w2v_model=gensim.models.KeyedVectors.load_word2vec_format('/home/kakade/Support_files/GoogleNews-vectors-negative300.bin', binary=True).word_vec(x)\n  File \"/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\", line 209, in load_word2vec_format\n    result.syn0 = zeros((vocab_size, vector_size), dtype=datatype)\nMemoryError\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:144)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:87)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=spark.read.csv(\"../Clean_Data_Frame.csv\",escape='\"',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample=train_data.filter(train_data[\"category_1\"]==\"Fashion\").drop(\"category_1\",\"org_price\",\"clarity\",\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer,StopWordsRemover,CountVectorizer\n",
    "from pyspark.sql.types import StructField,StringType,FloatType,StructType,IntegerType\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "def useful_token_func(col1,col2):\n",
    "    if len(col1)>col2:\n",
    "        return 0\n",
    "    else:\n",
    "        return col2-len(col1)\n",
    "useful_token = udf(useful_token_func, IntegerType())\n",
    "\n",
    "test_1 = test_sample.withColumn(\"title_no_sc1\", regexp_replace(test_sample[\"title\"], '[-/()]+', ' '))\n",
    "test_1 = test_1.withColumn(\"title_no_sc\", regexp_replace(test_1[\"title_no_sc1\"], '''['.]+''', ''))\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"title_no_sc\", outputCol=\"words\")\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"title_no_sc\", outputCol=\"regex_words\", pattern=\"\\\\W\")\n",
    "stop_words_remover = StopWordsRemover(inputCol=\"regex_words\", outputCol=\"no_stopwords\")\n",
    "\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "test_1 = tokenizer.transform(test_1)\n",
    "test_1=test_1.withColumn(\"tokens\", countTokens(test_1[\"words\"]))\n",
    "\n",
    "test_1 = regexTokenizer.transform(test_1)\n",
    "test_1=test_1.withColumn(\"regex_tokens\", useful_token(test_1[\"regex_words\"],test_1[\"tokens\"]))\n",
    "\n",
    "test_1 = stop_words_remover.transform(test_1)\n",
    "test_1=test_1.withColumn(\"sw_tokens\", useful_token(test_1[\"no_stopwords\"],test_1[\"tokens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1=test_1.drop(\"regex/org\",\"sw/org\",\"title\",\"title_no_sc1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'category_2',\n",
       " 'category_3',\n",
       " 'description',\n",
       " 'product_type',\n",
       " 'concise',\n",
       " 'title_no_sc',\n",
       " 'words',\n",
       " 'tokens',\n",
       " 'regex_words',\n",
       " 'regex_tokens',\n",
       " 'no_stopwords',\n",
       " 'sw_tokens']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|             index|      regex_tokens|         sw_tokens|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|              3165|              3165|              3165|\n",
      "|   mean| 17917.09636650869|1.0641390205371248|1.5197472353870458|\n",
      "| stddev|10503.571125659342|1.4562715605399985|1.7635170401090108|\n",
      "|    min|             10009|                 0|                 0|\n",
      "|    max|              9998|                23|                23|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_1.filter(\"concise==0\").select(\"index\",\"regex_tokens\",\"sw_tokens\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+------+------------------+\n",
      "|regex_tokens|sw_tokens|tokens|         regex/org|\n",
      "+------------+---------+------+------------------+\n",
      "|          12|       12|     8|               1.5|\n",
      "|          23|       22|    21|1.0952380952380953|\n",
      "|          17|       16|    15|1.1333333333333333|\n",
      "|          12|       12|     9|1.3333333333333333|\n",
      "|          13|       13|    10|               1.3|\n",
      "|          18|       18|    16|             1.125|\n",
      "|          29|       28|    26|1.1153846153846154|\n",
      "|          15|       14|    14|1.0714285714285714|\n",
      "|          19|       19|    16|            1.1875|\n",
      "|          16|       14|    14|1.1428571428571428|\n",
      "|          39|       36|    35|1.1142857142857143|\n",
      "|          19|       18|    18|1.0555555555555556|\n",
      "|          14|       14|    13|1.0769230769230769|\n",
      "|          12|       12|    11|1.0909090909090908|\n",
      "|          10|       10|     8|              1.25|\n",
      "|          13|       13|    10|               1.3|\n",
      "|          12|       12|     9|1.3333333333333333|\n",
      "|          13|       12|     9|1.4444444444444444|\n",
      "|          17|       16|    13|1.3076923076923077|\n",
      "|           9|        8|     7|1.2857142857142858|\n",
      "+------------+---------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_1.filter(test_1[\"regex/org\"]>1).select(\"regex_tokens\",\"sw_tokens\",\"tokens\",\"regex/org\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|regex_words                                                                                                                                                                                                                                                    |words                                                                                                                                                                                                                                                      |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[fashion, womens, multi, pocket, handbag, canvas, inclined, shoulderbag, _, black, _, x89]                                                                                                                                                                     |[fashion, womens, multi, pocket, handbag, canvas, inclined, shoulderbag�_�black��_\\x89]                                                                                                                                                                    |\n",
      "|[ul, li, apple, watch, accessoriesprice, lowered, apple, watch, strapseries, 1, and, 2, compatible, bands100, satisfaction, li, li, others, li, li, others, li, ul]                                                                                            |[<ul>, <li>apple, watch, accessoriesprice, lowered!, apple, watch, strapseries, 1, and, 2, compatible, bands100%, satisfaction<, li>, <li>others<, li>, <li>others<, li>, <, ul>]                                                                          |\n",
      "|[2016, fashion, snapback, baseball, cap, winterautum, hip, hop, flat, hat, bone, cap, for, men, amp, women, pink]                                                                                                                                              |[2016, fashion, snapback, baseball, cap, winterautum, hip, hop, flat, hat, bone, cap, for, men&amp;women, pink]                                                                                                                                            |\n",
      "|[fashion, womens, nylon, shoulder, bags, casual, messenger, bag, _, mixed, color, _]                                                                                                                                                                           |[fashion, womens, nylon, shoulder, bags, casual, messenger, bag�_�mixed, color�_�]                                                                                                                                                                         |\n",
      "|[tf, old, beijing, sleeve, shoes, cowboy, embroidery, womens, shoes, _, light, blue, _]                                                                                                                                                                        |[tf, old, beijing, sleeve, shoes, cowboy, embroidery, womens, shoes�_�light, blue�_�]                                                                                                                                                                      |\n",
      "|[sexy, thin, breathable, lace, vest, bra, anti, wrapped, chest, bra, straps, back, decoration, without, inner, sponge, black, intl]                                                                                                                            |[sexy, thin, breathable, lace, vest, bra,anti, wrapped, chest, bra, straps,back, decoration,without, inner, sponge,black, , , intl]                                                                                                                        |\n",
      "|[crocodile, pattern, large, capacity, womens, pu, leather, handbags, 2015, female, all, match, brief, one, shoulder, bag, ladies, big, black, bags, pink, black, red, blue, rose, red, beige, purple, intl]                                                    |[crocodile, pattern, large, capacity, womens, pu, leather, handbags, 2015, female, all, match, brief, one, shoulder, bag, ladies, big, black, bags, pink,black,red,blue,rose, red,beige,purple, , , , intl]                                                |\n",
      "|[fashion, women, o, neck, elegant, sexy, 3, 4, sleeve, bouffancy, lace, dress, all, match, dress]                                                                                                                                                              |[fashion, women, o, neck, elegant, sexy, 3, 4, sleeve, bouffancy, lace, dress,all, match, dress]                                                                                                                                                           |\n",
      "|[foreign, hedging, short, paragraph, oblique, zipper, jacket, men, slim, solid, color, fleece, hooded, sweater, 1401, tw79, _, blue, _]                                                                                                                        |[foreign, hedging, short, paragraph, oblique, zipper, jacket, men, slim, solid, color, fleece, hooded, sweater, 1401, tw79�_�blue�_�]                                                                                                                      |\n",
      "|[lace, up, martin, boots, 100, genuine, leather, motorcycle, boots, for, women, amp, men, plus, size, red]                                                                                                                                                     |[lace, up, martin, boots, 100%, genuine, leather, motorcycle, boots, for, women&amp;men, plus, size, red]                                                                                                                                                  |\n",
      "|[skadi, hot, girl, b, 516, women, girlfriend, wife, 2, pieces, sweet, romantic, sexy, lady, lingerie, baby, doll, dress, see, through, lace, sleepwear, night, gown, wedding, birthday, gift, with, panty, best, gift, _, red, _, free, mini, make, up, mirror]|[skadi, hot, girl, b, 516, women, girlfriend, wife, 2, pieces, sweet, romantic, sexy, lady, lingerie, baby, doll, dress, see, through, lace, sleepwear, night, gown, wedding, birthday, gift, with, panty, best, gift�_�red�_�free, mini, make, up, mirror]|\n",
      "|[100cm, 100cm, muslim, hijab, twill, silk, square, scarf, wraps, shawls, for, women, spring, small, flower, bowknot, print, sky, blue]                                                                                                                         |[100cm*100cm, muslim, hijab, twill, silk, square, scarf, wraps, shawls, for, women, spring, small, flower, bowknot, print, sky, blue]                                                                                                                      |\n",
      "|[zrong, womens, girl, long, sleeve, hoodie, tops, sweatshirt, pullover, army, green, nbsp, nbsp, nbsp]                                                                                                                                                         |[zrong, womens, girl, long, sleeve, hoodie, tops, sweatshirt, pullover, , army, green, &nbsp;&nbsp;&nbsp;]                                                                                                                                                 |\n",
      "|[mens, sports, shoes, running, shoes, men, fashion, sneakers, pl612b115c, black, amp, silver]                                                                                                                                                                  |[mens, sports, shoes, running, shoes, men, fashion, sneakers, pl612b115c, , black&amp;silver]                                                                                                                                                              |\n",
      "|[sports, surffashion, mens, swimming, trunks, beach, swimwear, l, amp, coffee]                                                                                                                                                                                 |[sports, surffashion, mens, swimming, trunks, beach, swimwear, l&amp;coffee]                                                                                                                                                                               |\n",
      "|[hemiks, mens, cargo, pants, casual, 100, cotton, loose, long, pants, _, gray, _]                                                                                                                                                                              |[hemiks, mens, cargo, pants, casual, 100%, cotton, loose, long, pants�_�gray�_�]                                                                                                                                                                           |\n",
      "|[men, fashion, boots, winter, snow, boots, ankle, boots, shoes, _, yellow, _]                                                                                                                                                                                  |[men, fashion, boots, winter, snow, boots, ankle, boots, shoes�_�yellow�_�]                                                                                                                                                                                |\n",
      "|[varsbaby, women, s, ultrathin, lace, transparent, half, cup, bra, set, _, pink, _]                                                                                                                                                                            |[varsbaby, women�۪s, ultrathin, lace, transparent, half, cup, bra, set�_�pink�_�]                                                                                                                                                                          |\n",
      "|[labelle, new, munafie, high, quality, set, of, 5, briefs, seamless, munafie, panties, black, white, grey, pink, beige]                                                                                                                                        |[labelle, new, munafie, high, quality, set, of, 5, briefs, seamless, munafie, panties, black,white,grey,pink,beige]                                                                                                                                        |\n",
      "|[anello, authentic, at, b0193a, nbsp, mouthpiece, filled, backpack, wine]                                                                                                                                                                                      |[anello, authentic, at, b0193a&nbsp;mouthpiece, filled, backpack, wine]                                                                                                                                                                                    |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_1.filter(test_1[\"regex/org\"]>1).select(\"regex_words\",\"words\",).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test_sample.withColumn(\"title_no_sc\", regexp_replace(test_sample[\"title\"], '[-]+', ' '))\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "test_1 = tokenizer.transform(test_sample)\n",
    "test_1=test_1.withColumn(\"tokens\", countTokens(test_1[\"words\"]))\n",
    "\n",
    "test_1 = regexTokenizer.transform(test_1)\n",
    "test_1=test_1.withColumn(\"regex_tokens\", countTokens(test_1[\"regex_words\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'title',\n",
       " 'category_2',\n",
       " 'category_3',\n",
       " 'description',\n",
       " 'product_type',\n",
       " 'concise',\n",
       " 'title_no_sc']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
