{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/kakade/spark')\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "spark = SparkSession.builder.appName(\"kakade\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,StringType,FloatType,StructType\n",
    "#Add header to data feature\n",
    "feature_schema = [StructField(\"country\", StringType(), True), StructField(\"sku_id\", StringType(), True), \\\n",
    "                  StructField(\"title\",StringType(), True), StructField(\"category_1\",StringType(), True), \\\n",
    "                  StructField(\"category_2\",StringType(), True), StructField(\"category_3\",StringType(), True), \\\n",
    "                  StructField(\"description\",StringType(), True), StructField(\"org_price\", FloatType(), True), \\\n",
    "                  StructField(\"product_type\",StringType(), True)]\n",
    "# country sku_id title category_1 category_2 category_3 short_description price product_type \n",
    "feature_struc = StructType(fields=feature_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = spark.read.csv(\"../Data/training/data_train.csv\",schema=feature_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0c2b4caa3ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train_feature.groupBy(\"category_1\").count().orderBy(\"count\",ascending=False).show(truncate=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmain_category\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"category_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count>5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_feature.category_1\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"main_category.category_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'col' is not defined"
     ]
    }
   ],
   "source": [
    "#most other category only contain <=5 products\n",
    "#filter products out of the main categories\n",
    "# train_feature.groupBy(\"category_1\").count().orderBy(\"count\",ascending=False).show(truncate=False)\n",
    "main_category=train_feature.groupBy(\"category_1\").count().filter(\"count>5\")\n",
    "train_feature = train_feature.join(main_category, col(\"train_feature.category_1\") == col(\"main_category.category_1\"), 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer,StopWordsRemover,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_extract_func(col):\n",
    "    soup=BeautifulSoup(col)\n",
    "    return soup.get_text()\n",
    "    return (1-col1/col2)**2\n",
    "html_extract = udf(html_extract_func, StringType())\n",
    "train_feature = train_feature.withColumn(\"html_extract\",html_extract(\"description\"))\n",
    "# train_feature.select(\"html_extract\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'html_extract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a9cd31d0ec1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdes_cat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"category_1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sku_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml_extract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(\\d+)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'html_extract'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mregexTokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"html_extract\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"description_token\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\\\W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdes_cat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdes_cat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstop_words_remover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStopWordsRemover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"description_token\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stop_words_filtered\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1020\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1021\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'html_extract'"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "des_cat_test = train_feature.select(\"category_1\",\"sku_id\",F.regexp_replace(train_feature.html_extract, '(\\d+)', ' ').alias('html_extract'))\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"html_extract\", outputCol=\"description_token\", pattern=\"\\\\W\")\n",
    "des_cat_test = regexTokenizer.transform(des_cat_test)\n",
    "stop_words_remover = StopWordsRemover(inputCol=\"description_token\", outputCol=\"stop_words_filtered\")\n",
    "des_cat_test = stop_words_remover.transform(des_cat_test)\n",
    "des_cat_test.select(\"stop_words_filtered\").show(truncate=False)\n",
    "#for text in des_cat_test.select(\"stop_words_filtered\"):\n",
    "#   print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##currency_exchange\n",
    "#set all price to PHP\n",
    "import pyspark.sql.functions as F\n",
    "from forex_python.converter import CurrencyRates\n",
    "cex = CurrencyRates()\n",
    "S2P=cex.get_rate(\"SGD\",\"PHP\")\n",
    "M2P=cex.get_rate(\"MYR\",\"PHP\")\n",
    "train_feature=train_feature.withColumn(\"price\", F.when(train_feature.country == \"my\", M2P*train_feature.org_price).when(train_feature.country == \"sg\", S2P*train_feature.org_price).otherwise(train_feature.org_price))\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|             price|org_price|\n",
      "+------------------+---------+\n",
      "|            597.31|     49.0|\n",
      "|           1560.32|    128.0|\n",
      "| 305.6032962799072|    25.07|\n",
      "|1438.4199999999998|    118.0|\n",
      "|1399.4120372009277|    114.8|\n",
      "|31681.809999999998|   2599.0|\n",
      "| 4741.787980957031|   388.99|\n",
      "|126.77599534988403|     10.4|\n",
      "|               0.0|      0.0|\n",
      "|            304.75|     25.0|\n",
      "|115.56119441986084|     9.48|\n",
      "| 950.8199999999999|     78.0|\n",
      "|189.55450232505797|    15.55|\n",
      "|6082.8099999999995|    499.0|\n",
      "|            1462.8|    120.0|\n",
      "|              null|     null|\n",
      "| 1031.273981399536|     84.6|\n",
      "|             365.7|     30.0|\n",
      "| 203.0853981399536|    16.66|\n",
      "|2072.2999999999997|    170.0|\n",
      "+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feature.select(\"price\",\"org_price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-----+\n",
      "|category_1                                                    |count|\n",
      "+--------------------------------------------------------------+-----+\n",
      "|Mobiles & Tablets                                             |7273 |\n",
      "|Home & Living                                                 |6042 |\n",
      "|Fashion                                                       |5729 |\n",
      "|Watches Sunglasses Jewellery                                  |4216 |\n",
      "|Health & Beauty                                               |4040 |\n",
      "|Computers & Laptops                                           |2882 |\n",
      "|TV, Audio / Video, Gaming & Wearables                         |2505 |\n",
      "|Cameras                                                       |1950 |\n",
      "|Home Appliances                                               |1583 |\n",
      "| 8GB                                                          |5    |\n",
      "| 4GB                                                          |5    |\n",
      "|A1466)                                                        |2    |\n",
      "| Black\"                                                       |2    |\n",
      "| Direct Shipping &amp; Free Installation in Klang Valley\"     |2    |\n",
      "|Soft-Touch Plastic 13 inch Cover for Apple MacBook Pro 13.3\"\"\"|1    |\n",
      "|W7Pro)\"                                                       |1    |\n",
      "|W10\"                                                          |1    |\n",
      "| Crystal-Black)\"                                              |1    |\n",
      "| BLACK + ASUS ORIGINAL DESIGN BACKPACK\"                       |1    |\n",
      "| W8.1) - FREE Office 365 Personal + Targus Backpack\"          |1    |\n",
      "+--------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feature.groupBy(\"category_1\").count().orderBy(\"count\",ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
